"""
å‹•çš„å¯¾è©±ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  - Streamlitç‰ˆ
èªã‚Šæ‰‹ã¨æ‰¹è©•å®¶ã®å¯¾è©±ã‚’è‡ªå‹•ç”Ÿæˆ
"""

import streamlit as st
import ollama
import json
import re
from datetime import datetime
from typing import Dict, List, Optional, Any
import os

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å‹•çš„å¯¾è©±ç”Ÿæˆ",
    page_icon="ğŸ­",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ­ å‹•çš„å¯¾è©±ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
st.caption("ãƒ†ãƒ¼ãƒã‹ã‚‰èªã‚Šæ‰‹ã¨æ‰¹è©•å®¶ã®å¯¾è©±ã‚’è‡ªå‹•ç”Ÿæˆ")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    available_models = [m.model for m in ollama.list().models]
    
    narrator_model = st.selectbox(
        "èªã‚Šæ‰‹ãƒ¢ãƒ‡ãƒ«",
        available_models,
        index=available_models.index("qwen2.5:7b") if "qwen2.5:7b" in available_models else 0
    )
    
    critic_model = st.selectbox(
        "æ‰¹è©•å®¶ãƒ¢ãƒ‡ãƒ«", 
        available_models,
        index=available_models.index("gemma3:4b") if "gemma3:4b" in available_models else 0
    )
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    with st.expander("è©³ç´°è¨­å®š", expanded=False):
        max_turns = st.slider("æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°", 4, 20, 8)
        narrator_temp = st.slider("èªã‚Šæ‰‹ã®å‰µé€ æ€§", 0.1, 1.0, 0.7, 0.1)
        critic_temp = st.slider("æ‰¹è©•å®¶ã®å³ã—ã•", 0.1, 1.0, 0.6, 0.1)

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
tab1, tab2, tab3 = st.tabs(["ğŸ¬ å¯¾è©±ç”Ÿæˆ", "ğŸ“Š åˆ†æ", "ğŸ“ å±¥æ­´"])

with tab1:
    # ãƒ†ãƒ¼ãƒé¸æŠ
    st.subheader("ğŸ“Œ ãƒ†ãƒ¼ãƒé¸æŠ")
    
    themes = [
        "ç«æ˜Ÿã‚³ãƒ­ãƒ‹ãƒ¼ã§ç™ºè¦‹ã•ã‚ŒãŸè¬ã®ä¿¡å·",
        "æ·±å¤œã®ã‚³ãƒ³ãƒ“ãƒ‹ã«ç¾ã‚ŒãŸé€æ˜äººé–“",
        "AIãƒ­ãƒœãƒƒãƒˆãŒè¦‹ãŸåˆã‚ã¦ã®å¤¢",
        "æ±Ÿæˆ¸æ™‚ä»£ã®å¯¿å¸å±‹ã«ç¾ã‚ŒãŸã‚¿ã‚¤ãƒ ãƒˆãƒ©ãƒ™ãƒ©ãƒ¼",
        "æ·±æµ·1ä¸‡ãƒ¡ãƒ¼ãƒˆãƒ«ã®ç ”ç©¶æ–½è¨­ã§èµ·ããŸäº‹ä»¶",
        "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®ä¸­ã«ç”Ÿã¾ã‚ŒãŸæ„è­˜",
        "æœˆé¢éƒ½å¸‚ã§ã®æ®ºäººäº‹ä»¶",
        "ã‚«ã‚¹ã‚¿ãƒ ï¼ˆè‡ªç”±å…¥åŠ›ï¼‰"
    ]
    
    col1, col2 = st.columns([3, 1])
    with col1:
        selected_theme = st.selectbox("ãƒ†ãƒ¼ãƒã‚’é¸æŠ", themes)
        
        if selected_theme == "ã‚«ã‚¹ã‚¿ãƒ ï¼ˆè‡ªç”±å…¥åŠ›ï¼‰":
            custom_theme = st.text_input("ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            if custom_theme:
                selected_theme = custom_theme
    
    with col2:
        generate_btn = st.button("ğŸ¬ å¯¾è©±ã‚’ç”Ÿæˆ", type="primary", use_container_width=True)
    
    # å¯¾è©±ç”Ÿæˆã‚¨ãƒªã‚¢
    if generate_btn and selected_theme != "ã‚«ã‚¹ã‚¿ãƒ ï¼ˆè‡ªç”±å…¥åŠ›ï¼‰":
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
        st.session_state.current_dialogue = []
        st.session_state.current_theme = selected_theme
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # å¯¾è©±è¡¨ç¤ºã‚¨ãƒªã‚¢
        dialogue_container = st.container()
        
        # æ‰¹è©•ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
        with st.spinner("ğŸ§  æ‰¹è©•è¨­å®šã‚’ç”Ÿæˆä¸­..."):
            critic_context = generate_critic_context(selected_theme, critic_model)
            st.session_state.critic_context = critic_context
        
        # å¯¾è©±ç”Ÿæˆãƒ«ãƒ¼ãƒ—
        for turn in range(max_turns):
            progress = (turn + 1) / max_turns
            progress_bar.progress(progress)
            
            # èªã‚Šæ‰‹ã®ç™ºè¨€
            if turn == 0 or st.session_state.get("next_speaker") != "critic":
                status_text.text(f"èªã‚Šæ‰‹ãŒè©±ã—ã¦ã„ã¾ã™... (ã‚¿ãƒ¼ãƒ³ {turn+1}/{max_turns})")
                narrator_text = generate_narrator_response(
                    selected_theme,
                    narrator_model,
                    narrator_temp,
                    turn,
                    st.session_state.current_dialogue
                )
                
                with dialogue_container:
                    with st.chat_message("assistant", avatar="ğŸ­"):
                        st.write(f"**èªã‚Šæ‰‹**: {narrator_text}")
                
                st.session_state.current_dialogue.append({
                    "role": "narrator",
                    "content": narrator_text,
                    "turn": turn
                })
            
            # æ‰¹è©•å®¶ã®ç™ºè¨€
            if turn < max_turns - 1:
                status_text.text(f"æ‰¹è©•å®¶ãŒè€ƒãˆã¦ã„ã¾ã™... (ã‚¿ãƒ¼ãƒ³ {turn+1}/{max_turns})")
                critic_text = generate_critic_response(
                    narrator_text,
                    critic_model,
                    critic_temp,
                    critic_context,
                    turn
                )
                
                with dialogue_container:
                    with st.chat_message("user", avatar="ğŸ”"):
                        st.write(f"**æ‰¹è©•å®¶**: {critic_text}")
                
                st.session_state.current_dialogue.append({
                    "role": "critic",
                    "content": critic_text,
                    "turn": turn
                })
        
        progress_bar.progress(1.0)
        status_text.text("âœ… å¯¾è©±ç”Ÿæˆå®Œäº†ï¼")
        
        # ä¿å­˜ãƒœã‚¿ãƒ³
        if st.button("ğŸ’¾ å¯¾è©±ã‚’ä¿å­˜"):
            save_dialogue(st.session_state.current_dialogue, selected_theme)
            st.success("ä¿å­˜ã—ã¾ã—ãŸï¼")

with tab2:
    st.subheader("ğŸ“Š å¯¾è©±åˆ†æ")
    
    if "current_dialogue" in st.session_state and st.session_state.current_dialogue:
        analysis = analyze_dialogue(st.session_state.current_dialogue)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç·ã‚¿ãƒ¼ãƒ³æ•°", analysis["total_turns"])
        with col2:
            st.metric("çŸ›ç›¾æŒ‡æ‘˜", analysis["contradiction_count"])
        with col3:
            st.metric("å¹³å‡æ–‡å­—æ•°", f"{analysis['avg_length']:.1f}")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        if analysis["patterns"]:
            st.subheader("æ‰¹è©•ãƒ‘ã‚¿ãƒ¼ãƒ³")
            st.bar_chart(analysis["patterns"])
        
        # æ‰¹è©•ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
        if "critic_context" in st.session_state:
            with st.expander("æ‰¹è©•è¨­å®šè©³ç´°"):
                st.json(st.session_state.critic_context)
    else:
        st.info("å¯¾è©±ã‚’ç”Ÿæˆã™ã‚‹ã¨åˆ†æçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™")

with tab3:
    st.subheader("ğŸ“ ä¿å­˜æ¸ˆã¿å¯¾è©±")
    
    # å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
    if os.path.exists("data/dialogues"):
        files = sorted([f for f in os.listdir("data/dialogues") if f.endswith(".json")], reverse=True)
        
        if files:
            selected_file = st.selectbox("å±¥æ­´ã‚’é¸æŠ", files)
            
            if st.button("ğŸ“‚ èª­ã¿è¾¼ã¿"):
                with open(f"data/dialogues/{selected_file}", "r", encoding="utf-8") as f:
                    data = json.load(f)
                    
                st.write(f"**ãƒ†ãƒ¼ãƒ**: {data['theme']}")
                st.write(f"**ç”Ÿæˆæ—¥æ™‚**: {data['timestamp']}")
                
                for item in data['dialogue']:
                    role = "ğŸ­ èªã‚Šæ‰‹" if item['role'] == 'narrator' else "ğŸ” æ‰¹è©•å®¶"
                    st.write(f"{role}: {item['content']}")
        else:
            st.info("ä¿å­˜æ¸ˆã¿ã®å¯¾è©±ãŒã‚ã‚Šã¾ã›ã‚“")

# ============ ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ============

def generate_critic_context(theme: str, model: str) -> Dict[str, Any]:
    """æ‰¹è©•ç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
    prompt = f"""
ãƒ†ãƒ¼ãƒã€Œ{theme}ã€ã®ç‰©èªã‚’æ‰¹è©•ã™ã‚‹ãŸã‚ã®è¨­å®šã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ï¼ˆèª¬æ˜ä¸è¦ï¼‰:
{{
  "facts": ["é‡è¦ãªäº‹å®Ÿ1", "é‡è¦ãªäº‹å®Ÿ2", "é‡è¦ãªäº‹å®Ÿ3"],
  "contradictions": ["ã‚ˆãã‚ã‚‹çŸ›ç›¾1", "ã‚ˆãã‚ã‚‹çŸ›ç›¾2"],
  "personality": "æ‰¹è©•è€…ã®æ€§æ ¼",
  "focus": ["æ³¨ç›®ç‚¹1", "æ³¨ç›®ç‚¹2"],
  "forbidden": ["å­˜åœ¨ã—ãªã„ã‚‚ã®1", "å­˜åœ¨ã—ãªã„ã‚‚ã®2"]
}}
"""
    
    response = ollama.chat(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        options={"temperature": 0.3, "num_predict": 500}
    )
    
    content = response['message']['content']
    
    # JSONæŠ½å‡º
    try:
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
    except:
        pass
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return {
        "facts": ["ç‰©ç†æ³•å‰‡ã«å¾“ã†", "è«–ç†çš„æ•´åˆæ€§ãŒå¿…è¦", "å› æœé–¢ä¿‚ãŒæ˜ç¢º"],
        "contradictions": ["å‰å¾Œã®çŸ›ç›¾", "è¨­å®šã®ç„¡è¦–"],
        "personality": "æ‡ç–‘çš„",
        "focus": ["ä¸€è²«æ€§", "è«–ç†æ€§"],
        "forbidden": ["çŸ›ç›¾", "éè«–ç†çš„å±•é–‹"]
    }

def generate_narrator_response(theme: str, model: str, temperature: float, turn: int, dialogue: List) -> str:
    """èªã‚Šæ‰‹ã®å¿œç­”ç”Ÿæˆ"""
    
    if turn == 0:
        prompt = f"ã€Œ{theme}ã€ã®ç‰©èªã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚å…·ä½“çš„ãªå ´é¢ã‹ã‚‰2æ–‡ã§ã€‚"
    else:
        last_critic = dialogue[-1]['content'] if dialogue and dialogue[-1]['role'] == 'critic' else ""
        prompt = f"æ‰¹è©•ã€Œ{last_critic}ã€ã‚’å—ã‘ã¦ã€ç‰©èªã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚2æ–‡ã§ã€‚"
    
    response = ollama.chat(
        model=model,
        messages=[
            {"role": "system", "content": f"ã‚ãªãŸã¯ã€Œ{theme}ã€ã®ç‰©èªã‚’èªã‚‹èªã‚Šæ‰‹ã§ã™ã€‚"},
            {"role": "user", "content": prompt}
        ],
        options={"temperature": temperature, "num_predict": 100}
    )
    
    text = response['message']['content']
    
    # 2æ–‡ã«åˆ¶é™
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
    sentences = [s for s in sentences if s.strip()][:2]
    return 'ã€‚'.join(sentences) + 'ã€‚'

def generate_critic_response(narrator_text: str, model: str, temperature: float, context: Dict, turn: int) -> str:
    """æ‰¹è©•å®¶ã®å¿œç­”ç”Ÿæˆ"""
    
    system_prompt = f"""
ã‚ãªãŸã¯{context.get('personality', 'æ‡ç–‘çš„')}ãªæ‰¹è©•å®¶ã§ã™ã€‚
é‡è¦ãªäº‹å®Ÿ: {', '.join(context.get('facts', [])[:2])}
å­˜åœ¨ã—ã¦ã¯ã„ã‘ãªã„ã‚‚ã®: {', '.join(context.get('forbidden', []))}
è¿”ç­”ã¯15æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«ã€‚
"""
    
    response = ollama.chat(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"èªã‚Šæ‰‹: {narrator_text}\n\nçŸ­ãåå¿œã—ã¦ãã ã•ã„ã€‚"}
        ],
        options={"temperature": temperature, "num_predict": 40}
    )
    
    text = response['message']['content']
    
    # é•·ã•åˆ¶é™
    if len(text) > 20:
        text = text[:20]
    
    return text

def analyze_dialogue(dialogue: List[Dict]) -> Dict[str, Any]:
    """å¯¾è©±ã®åˆ†æ"""
    analysis = {
        "total_turns": len(dialogue),
        "contradiction_count": 0,
        "patterns": {},
        "avg_length": 0
    }
    
    lengths = []
    for item in dialogue:
        lengths.append(len(item['content']))
        
        # æ‰¹è©•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        if item['role'] == 'critic':
            if "ãªã„" in item['content'] or "ãŠã‹ã—ã„" in item['content']:
                analysis["contradiction_count"] += 1
                analysis["patterns"]["çŸ›ç›¾æŒ‡æ‘˜"] = analysis["patterns"].get("çŸ›ç›¾æŒ‡æ‘˜", 0) + 1
            elif "ï¼Ÿ" in item['content']:
                analysis["patterns"]["è³ªå•"] = analysis["patterns"].get("è³ªå•", 0) + 1
            else:
                analysis["patterns"]["ç›¸æ§Œ"] = analysis["patterns"].get("ç›¸æ§Œ", 0) + 1
    
    if lengths:
        analysis["avg_length"] = sum(lengths) / len(lengths)
    
    return analysis

def save_dialogue(dialogue: List[Dict], theme: str):
    """å¯¾è©±ã‚’ä¿å­˜"""
    os.makedirs("data/dialogues", exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"data/dialogues/dialogue_{timestamp}.json"
    
    data = {
        "theme": theme,
        "dialogue": dialogue,
        "timestamp": timestamp,
        "analysis": analyze_dialogue(dialogue)
    }
    
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)