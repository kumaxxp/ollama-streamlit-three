"""
å‹•çš„å¯¾è©±ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  - Streamlitç‰ˆ
èªã‚Šæ‰‹ã¨æ‰¹è©•å®¶ã®å¯¾è©±ã‚’è‡ªå‹•ç”Ÿæˆ
"""

import streamlit as st
import ollama
import json
import re
from datetime import datetime
from typing import Dict, List, Optional, Any
import os

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å‹•çš„å¯¾è©±ç”Ÿæˆ",
    page_icon="ğŸ­",
    layout="wide"
)

# ============ ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆå…ˆã«å®šç¾©ï¼‰ ============

def get_available_models():
    """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    try:
        models_response = ollama.list()
        available_models = []
        
        # APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ§‹é€ ã«å¿œã˜ã¦å‡¦ç†
        if hasattr(models_response, 'models'):
            # æ–°ã—ã„APIå½¢å¼
            for model in models_response.models:
                if hasattr(model, 'model'):
                    available_models.append(model.model)
                elif hasattr(model, 'name'):
                    available_models.append(model.name)
                elif isinstance(model, dict) and 'name' in model:
                    available_models.append(model['name'])
                elif isinstance(model, str):
                    available_models.append(model)
        elif isinstance(models_response, dict) and 'models' in models_response:
            # è¾æ›¸å½¢å¼
            for model in models_response['models']:
                if isinstance(model, dict) and 'name' in model:
                    available_models.append(model['name'])
                elif isinstance(model, str):
                    available_models.append(model)
        elif isinstance(models_response, list):
            # ãƒªã‚¹ãƒˆå½¢å¼
            for model in models_response:
                if isinstance(model, dict) and 'name' in model:
                    available_models.append(model['name'])
                elif isinstance(model, str):
                    available_models.append(model)
        
        # ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not available_models:
            st.warning("ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            # ã‚ˆãä½¿ã‚ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦æä¾›
            available_models = ["qwen2.5:7b", "gemma3:4b", "llama3.2:3b"]
            
            # å®Ÿéš›ã«åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
            actually_available = []
            for model in available_models:
                try:
                    # ãƒ†ã‚¹ãƒˆå‘¼ã³å‡ºã—
                    ollama.chat(
                        model=model,
                        messages=[{"role": "user", "content": "test"}],
                        options={"num_predict": 1}
                    )
                    actually_available.append(model)
                except:
                    pass
            
            if actually_available:
                available_models = actually_available
            else:
                st.error("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`ollama pull qwen2.5:7b`ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                return ["qwen2.5:7b"]  # ã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚æœ€ä½é™è¿”ã™
                
        return available_models
        
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        st.info("ãƒ‡ãƒãƒƒã‚°: `ollama list`ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return ["qwen2.5:7b", "gemma3:4b"]  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

def generate_critic_context(theme: str, model: str) -> Dict[str, Any]:
    """æ‰¹è©•ç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
    prompt = f"""
ãƒ†ãƒ¼ãƒã€Œ{theme}ã€ã®ç‰©èªã‚’æ‰¹è©•ã™ã‚‹ãŸã‚ã®è¨­å®šã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ï¼ˆèª¬æ˜ä¸è¦ï¼‰:
{{
  "facts": ["é‡è¦ãªäº‹å®Ÿ1", "é‡è¦ãªäº‹å®Ÿ2", "é‡è¦ãªäº‹å®Ÿ3"],
  "contradictions": ["ã‚ˆãã‚ã‚‹çŸ›ç›¾1", "ã‚ˆãã‚ã‚‹çŸ›ç›¾2"],
  "personality": "æ‰¹è©•è€…ã®æ€§æ ¼",
  "focus": ["æ³¨ç›®ç‚¹1", "æ³¨ç›®ç‚¹2"],
  "forbidden": ["å­˜åœ¨ã—ãªã„ã‚‚ã®1", "å­˜åœ¨ã—ãªã„ã‚‚ã®2"]
}}
"""
    
    try:
        response = ollama.chat(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            options={"temperature": 0.3, "num_predict": 500}
        )
        
        content = response['message']['content']
        
        # JSONæŠ½å‡º
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
    except Exception as e:
        st.warning(f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return {
        "facts": ["ç‰©ç†æ³•å‰‡ã«å¾“ã†", "è«–ç†çš„æ•´åˆæ€§ãŒå¿…è¦", "å› æœé–¢ä¿‚ãŒæ˜ç¢º"],
        "contradictions": ["å‰å¾Œã®çŸ›ç›¾", "è¨­å®šã®ç„¡è¦–"],
        "personality": "æ‡ç–‘çš„",
        "focus": ["ä¸€è²«æ€§", "è«–ç†æ€§"],
        "forbidden": ["çŸ›ç›¾", "éè«–ç†çš„å±•é–‹"]
    }

def generate_narrator_response(theme: str, model: str, temperature: float, turn: int, dialogue: List) -> str:
    """èªã‚Šæ‰‹ã®å¿œç­”ç”Ÿæˆ"""
    
    if turn == 0:
        prompt = f"ã€Œ{theme}ã€ã®ç‰©èªã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚å…·ä½“çš„ãªå ´é¢ã‹ã‚‰2æ–‡ã§ã€‚"
    else:
        last_critic = dialogue[-1]['content'] if dialogue and dialogue[-1]['role'] == 'critic' else ""
        prompt = f"æ‰¹è©•ã€Œ{last_critic}ã€ã‚’å—ã‘ã¦ã€ç‰©èªã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚2æ–‡ã§ã€‚"
    
    try:
        response = ollama.chat(
            model=model,
            messages=[
                {"role": "system", "content": f"ã‚ãªãŸã¯ã€Œ{theme}ã€ã®ç‰©èªã‚’èªã‚‹èªã‚Šæ‰‹ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            options={"temperature": temperature, "num_predict": 100}
        )
        
        text = response['message']['content']
        
        # 2æ–‡ã«åˆ¶é™
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        sentences = [s for s in sentences if s.strip()][:2]
        return 'ã€‚'.join(sentences) + 'ã€‚'
        
    except Exception as e:
        return f"[ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}]"

def generate_critic_response(narrator_text: str, model: str, temperature: float, context: Dict, turn: int) -> str:
    """æ‰¹è©•å®¶ã®å¿œç­”ç”Ÿæˆ"""
    
    system_prompt = f"""
ã‚ãªãŸã¯{context.get('personality', 'æ‡ç–‘çš„')}ãªæ‰¹è©•å®¶ã§ã™ã€‚
é‡è¦ãªäº‹å®Ÿ: {', '.join(context.get('facts', [])[:2])}
å­˜åœ¨ã—ã¦ã¯ã„ã‘ãªã„ã‚‚ã®: {', '.join(context.get('forbidden', []))}
è¿”ç­”ã¯15æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«ã€‚
"""
    
    try:
        response = ollama.chat(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"èªã‚Šæ‰‹: {narrator_text}\n\nçŸ­ãåå¿œã—ã¦ãã ã•ã„ã€‚"}
            ],
            options={"temperature": temperature, "num_predict": 40}
        )
        
        text = response['message']['content']
        
        # é•·ã•åˆ¶é™
        if len(text) > 20:
            text = text[:20]
        
        return text
        
    except Exception as e:
        return f"[ã‚¨ãƒ©ãƒ¼]"

def analyze_dialogue(dialogue: List[Dict]) -> Dict[str, Any]:
    """å¯¾è©±ã®åˆ†æ"""
    analysis = {
        "total_turns": len(dialogue),
        "contradiction_count": 0,
        "patterns": {},
        "avg_length": 0
    }
    
    lengths = []
    for item in dialogue:
        lengths.append(len(item['content']))
        
        # æ‰¹è©•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        if item['role'] == 'critic':
            if "ãªã„" in item['content'] or "ãŠã‹ã—ã„" in item['content']:
                analysis["contradiction_count"] += 1
                analysis["patterns"]["çŸ›ç›¾æŒ‡æ‘˜"] = analysis["patterns"].get("çŸ›ç›¾æŒ‡æ‘˜", 0) + 1
            elif "ï¼Ÿ" in item['content']:
                analysis["patterns"]["è³ªå•"] = analysis["patterns"].get("è³ªå•", 0) + 1
            else:
                analysis["patterns"]["ç›¸æ§Œ"] = analysis["patterns"].get("ç›¸æ§Œ", 0) + 1
    
    if lengths:
        analysis["avg_length"] = sum(lengths) / len(lengths)
    
    return analysis

def save_dialogue(dialogue: List[Dict], theme: str):
    """å¯¾è©±ã‚’ä¿å­˜"""
    os.makedirs("data/dialogues", exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"data/dialogues/dialogue_{timestamp}.json"
    
    data = {
        "theme": theme,
        "dialogue": dialogue,
        "timestamp": timestamp,
        "analysis": analyze_dialogue(dialogue)
    }
    
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    return filename

# ============ ãƒ¡ã‚¤ãƒ³UI ============

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ­ å‹•çš„å¯¾è©±ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
st.caption("ãƒ†ãƒ¼ãƒã‹ã‚‰èªã‚Šæ‰‹ã¨æ‰¹è©•å®¶ã®å¯¾è©±ã‚’è‡ªå‹•ç”Ÿæˆ")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # ãƒ¢ãƒ‡ãƒ«å–å¾—
    available_models = get_available_models()
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    narrator_model = st.selectbox(
        "èªã‚Šæ‰‹ãƒ¢ãƒ‡ãƒ«",
        available_models,
        index=available_models.index("qwen2.5:7b") if "qwen2.5:7b" in available_models else 0,
        key="narrator_model_select"
    )
    
    critic_model = st.selectbox(
        "æ‰¹è©•å®¶ãƒ¢ãƒ‡ãƒ«", 
        available_models,
        index=available_models.index("gemma3:4b") if "gemma3:4b" in available_models else 0,
        key="critic_model_select"
    )
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    with st.expander("è©³ç´°è¨­å®š", expanded=False):
        max_turns = st.slider("æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°", 4, 20, 8)
        narrator_temp = st.slider("èªã‚Šæ‰‹ã®å‰µé€ æ€§", 0.1, 1.0, 0.7, 0.1)
        critic_temp = st.slider("æ‰¹è©•å®¶ã®å³ã—ã•", 0.1, 1.0, 0.6, 0.1)
        
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    with st.expander("ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=False):
        st.code(f"æ¤œå‡ºã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«æ•°: {len(available_models)}")
        st.code(f"ãƒ¢ãƒ‡ãƒ«: {', '.join(available_models[:5])}")

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
tab1, tab2, tab3 = st.tabs(["ğŸ¬ å¯¾è©±ç”Ÿæˆ", "ğŸ“Š åˆ†æ", "ğŸ“ å±¥æ­´"])

with tab1:
    # ãƒ†ãƒ¼ãƒé¸æŠ
    st.subheader("ğŸ“Œ ãƒ†ãƒ¼ãƒé¸æŠ")
    
    themes = [
        "ç«æ˜Ÿã‚³ãƒ­ãƒ‹ãƒ¼ã§ç™ºè¦‹ã•ã‚ŒãŸè¬ã®ä¿¡å·",
        "æ·±å¤œã®ã‚³ãƒ³ãƒ“ãƒ‹ã«ç¾ã‚ŒãŸé€æ˜äººé–“",
        "AIãƒ­ãƒœãƒƒãƒˆãŒè¦‹ãŸåˆã‚ã¦ã®å¤¢",
        "æ±Ÿæˆ¸æ™‚ä»£ã®å¯¿å¸å±‹ã«ç¾ã‚ŒãŸã‚¿ã‚¤ãƒ ãƒˆãƒ©ãƒ™ãƒ©ãƒ¼",
        "æ·±æµ·1ä¸‡ãƒ¡ãƒ¼ãƒˆãƒ«ã®ç ”ç©¶æ–½è¨­ã§èµ·ããŸäº‹ä»¶",
        "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®ä¸­ã«ç”Ÿã¾ã‚ŒãŸæ„è­˜",
        "æœˆé¢éƒ½å¸‚ã§ã®æ®ºäººäº‹ä»¶",
        "ã‚«ã‚¹ã‚¿ãƒ ï¼ˆè‡ªç”±å…¥åŠ›ï¼‰"
    ]
    
    col1, col2 = st.columns([3, 1])
    with col1:
        selected_theme = st.selectbox("ãƒ†ãƒ¼ãƒã‚’é¸æŠ", themes, key="theme_select")
        
        if selected_theme == "ã‚«ã‚¹ã‚¿ãƒ ï¼ˆè‡ªç”±å…¥åŠ›ï¼‰":
            custom_theme = st.text_input("ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", key="custom_theme_input")
            if custom_theme:
                selected_theme = custom_theme
    
    with col2:
        generate_btn = st.button("ğŸ¬ å¯¾è©±ã‚’ç”Ÿæˆ", type="primary", use_container_width=True)
    
    # å¯¾è©±ç”Ÿæˆã‚¨ãƒªã‚¢
    if generate_btn and selected_theme != "ã‚«ã‚¹ã‚¿ãƒ ï¼ˆè‡ªç”±å…¥åŠ›ï¼‰":
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
        st.session_state.current_dialogue = []
        st.session_state.current_theme = selected_theme
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # å¯¾è©±è¡¨ç¤ºã‚¨ãƒªã‚¢
        dialogue_container = st.container()
        
        try:
            # æ‰¹è©•ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            with st.spinner("ğŸ§  æ‰¹è©•è¨­å®šã‚’ç”Ÿæˆä¸­..."):
                critic_context = generate_critic_context(selected_theme, critic_model)
                st.session_state.critic_context = critic_context
                
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
                with st.expander("ç”Ÿæˆã•ã‚ŒãŸæ‰¹è©•è¨­å®š", expanded=False):
                    st.json(critic_context)
            
            # å¯¾è©±ç”Ÿæˆãƒ«ãƒ¼ãƒ—
            narrator_text = ""
            for turn in range(max_turns):
                progress = (turn + 1) / max_turns
                progress_bar.progress(progress)
                
                # èªã‚Šæ‰‹ã®ç™ºè¨€
                status_text.text(f"èªã‚Šæ‰‹ãŒè©±ã—ã¦ã„ã¾ã™... (ã‚¿ãƒ¼ãƒ³ {turn+1}/{max_turns})")
                narrator_text = generate_narrator_response(
                    selected_theme,
                    narrator_model,
                    narrator_temp,
                    turn,
                    st.session_state.current_dialogue
                )
                
                with dialogue_container:
                    with st.chat_message("assistant", avatar="ğŸ­"):
                        st.write(f"**èªã‚Šæ‰‹**: {narrator_text}")
                
                st.session_state.current_dialogue.append({
                    "role": "narrator",
                    "content": narrator_text,
                    "turn": turn
                })
                
                # æ‰¹è©•å®¶ã®ç™ºè¨€
                if turn < max_turns - 1:
                    status_text.text(f"æ‰¹è©•å®¶ãŒè€ƒãˆã¦ã„ã¾ã™... (ã‚¿ãƒ¼ãƒ³ {turn+1}/{max_turns})")
                    critic_text = generate_critic_response(
                        narrator_text,
                        critic_model,
                        critic_temp,
                        critic_context,
                        turn
                    )
                    
                    with dialogue_container:
                        with st.chat_message("user", avatar="ğŸ”"):
                            st.write(f"**æ‰¹è©•å®¶**: {critic_text}")
                    
                    st.session_state.current_dialogue.append({
                        "role": "critic",
                        "content": critic_text,
                        "turn": turn
                    })
            
            progress_bar.progress(1.0)
            status_text.text("âœ… å¯¾è©±ç”Ÿæˆå®Œäº†ï¼")
            
            # ä¿å­˜ãƒœã‚¿ãƒ³
            col1, col2, col3 = st.columns([1, 1, 2])
            with col1:
                if st.button("ğŸ’¾ å¯¾è©±ã‚’ä¿å­˜", key="save_dialogue_btn"):
                    filename = save_dialogue(st.session_state.current_dialogue, selected_theme)
                    st.success(f"ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
            with col2:
                if st.button("ğŸ”„ ã‚‚ã†ä¸€åº¦ç”Ÿæˆ", key="regenerate_btn"):
                    st.rerun()
                    
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.info("ãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ããƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            with st.expander("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±"):
                st.code(str(e))

with tab2:
    st.subheader("ğŸ“Š å¯¾è©±åˆ†æ")
    
    if "current_dialogue" in st.session_state and st.session_state.current_dialogue:
        analysis = analyze_dialogue(st.session_state.current_dialogue)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç·ã‚¿ãƒ¼ãƒ³æ•°", analysis["total_turns"])
        with col2:
            st.metric("çŸ›ç›¾æŒ‡æ‘˜", analysis["contradiction_count"])
        with col3:
            st.metric("å¹³å‡æ–‡å­—æ•°", f"{analysis['avg_length']:.1f}")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        if analysis["patterns"]:
            st.subheader("æ‰¹è©•ãƒ‘ã‚¿ãƒ¼ãƒ³")
            st.bar_chart(analysis["patterns"])
        
        # å¯¾è©±å…¨ä½“ã®è¡¨ç¤º
        with st.expander("å¯¾è©±å…¨æ–‡"):
            for item in st.session_state.current_dialogue:
                role = "ğŸ­ èªã‚Šæ‰‹" if item['role'] == 'narrator' else "ğŸ” æ‰¹è©•å®¶"
                st.write(f"{role}: {item['content']}")
        
        # æ‰¹è©•ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
        if "critic_context" in st.session_state:
            with st.expander("æ‰¹è©•è¨­å®šè©³ç´°"):
                st.json(st.session_state.critic_context)
    else:
        st.info("å¯¾è©±ã‚’ç”Ÿæˆã™ã‚‹ã¨åˆ†æçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™")

with tab3:
    st.subheader("ğŸ“ ä¿å­˜æ¸ˆã¿å¯¾è©±")
    
    # å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
    dialogue_dir = "data/dialogues"
    if os.path.exists(dialogue_dir):
        files = sorted([f for f in os.listdir(dialogue_dir) if f.endswith(".json")], reverse=True)
        
        if files:
            selected_file = st.selectbox("å±¥æ­´ã‚’é¸æŠ", files, key="history_select")
            
            col1, col2 = st.columns([1, 5])
            with col1:
                load_btn = st.button("ğŸ“‚ èª­ã¿è¾¼ã¿", key="load_history_btn")
            
            if load_btn:
                try:
                    with open(f"{dialogue_dir}/{selected_file}", "r", encoding="utf-8") as f:
                        data = json.load(f)
                        
                    st.write(f"**ãƒ†ãƒ¼ãƒ**: {data['theme']}")
                    st.write(f"**ç”Ÿæˆæ—¥æ™‚**: {data.get('timestamp', 'ä¸æ˜')}")
                    
                    # åˆ†æçµæœè¡¨ç¤º
                    if 'analysis' in data:
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ç·ã‚¿ãƒ¼ãƒ³æ•°", data['analysis']['total_turns'])
                        with col2:
                            st.metric("çŸ›ç›¾æŒ‡æ‘˜", data['analysis'].get('contradiction_count', 0))
                        with col3:
                            st.metric("å¹³å‡æ–‡å­—æ•°", f"{data['analysis'].get('avg_length', 0):.1f}")
                    
                    st.divider()
                    
                    # å¯¾è©±è¡¨ç¤º
                    for item in data['dialogue']:
                        role = "ğŸ­ èªã‚Šæ‰‹" if item['role'] == 'narrator' else "ğŸ” æ‰¹è©•å®¶"
                        st.write(f"{role}: {item['content']}")
                        
                except Exception as e:
                    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.info("ä¿å­˜æ¸ˆã¿ã®å¯¾è©±ãŒã‚ã‚Šã¾ã›ã‚“")
    else:
        st.info("ã¾ã å¯¾è©±ãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        os.makedirs(dialogue_dir, exist_ok=True)