#!/usr/bin/env python3
"""
é•·ã•åˆ¶å¾¡æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Phase 1å®Ÿè£…ã®å‹•ä½œç¢ºèªç”¨
"""

import asyncio
import json
from app.core.dialogue_manager import DialogueManager
from app.core.director import AutonomousDirector
import ollama

async def test_length_control():
    """é•·ã•åˆ¶å¾¡æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    print("=" * 60)
    print("ğŸ“ é•·ã•åˆ¶å¾¡æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # Ollamaã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    client = ollama.Client()
    
    # DialogueManageråˆæœŸåŒ–
    manager = DialogueManager(client, director_model="gemma3:4b")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®å¯¾è©±å±¥æ­´ã‚’ä½œæˆ
    test_dialogues = [
        # çŸ­ã„å¿œç­”ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        {
            "dialogues": [
                {"speaker": "ã‚„ãª", "listener": "ã‚ã‚†", "message": "ã†ã‚“"},
                {"speaker": "ã‚ã‚†", "listener": "ã‚„ãªå§‰ã•ã¾", "message": "ã¯ã„"},
                {"speaker": "ã‚„ãª", "listener": "ã‚ã‚†", "message": "ãã†ã ã­"},
            ],
            "expected": "è©³ç´°",
            "scenario": "çŸ­ã™ãã‚‹å¿œç­”"
        },
        # é•·ã„å¿œç­”ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        {
            "dialogues": [
                {"speaker": "ã‚„ãª", "listener": "ã‚ã‚†", "message": "ç§ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚ˆã‚‹ã¨ã€" + "ã“ã‚Œã¯éå¸¸ã«èˆˆå‘³æ·±ã„å•é¡Œã§ã€" * 20},
                {"speaker": "ã‚ã‚†", "listener": "ã‚„ãªå§‰ã•ã¾", "message": "ç¢ºã‹ã«ãã®é€šã‚Šã§ã™ãŒã€" + "åˆ¥ã®è¦³ç‚¹ã‹ã‚‰è¦‹ã‚‹ã¨ã€" * 20},
            ],
            "expected": "ç°¡æ½”",
            "scenario": "é•·ã™ãã‚‹å¿œç­”"
        },
        # ãƒãƒ©ãƒ³ã‚¹ã®æ‚ªã„ãƒ‘ã‚¿ãƒ¼ãƒ³
        {
            "dialogues": [
                {"speaker": "ã‚„ãª", "listener": "ã‚ã‚†", "message": "ã“ã‚Œã«ã¤ã„ã¦ç§ã®æ„è¦‹ã‚’è©³ã—ãèª¬æ˜ã™ã‚‹ã¨" + "ã€" * 50},
                {"speaker": "ã‚ã‚†", "listener": "ã‚„ãªå§‰ã•ã¾", "message": "ãªã‚‹ã»ã©"},
                {"speaker": "ã‚„ãª", "listener": "ã‚ã‚†", "message": "ã•ã‚‰ã«ä»˜ã‘åŠ ãˆã‚‹ã¨" + "ã€" * 40},
                {"speaker": "ã‚ã‚†", "listener": "ã‚„ãªå§‰ã•ã¾", "message": "ç¢ºã‹ã«"},
            ],
            "expected": "imbalanced",
            "scenario": "ã‚¢ãƒ³ãƒãƒ©ãƒ³ã‚¹ãªå¯¾è©±"
        }
    ]
    
    for i, test_case in enumerate(test_dialogues, 1):
        print(f"\n--- ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i}: {test_case['scenario']} ---")
        
        # é•·ã•åˆ†æã‚’å®Ÿè¡Œ
        analysis = manager.director.analyze_response_lengths(test_case['dialogues'])
        
        print(f"å¹³å‡é•·ã•: {analysis['average_length']:.0f}æ–‡å­—")
        print(f"ãƒˆãƒ¬ãƒ³ãƒ‰: {analysis['recent_trend']}")
        print(f"ãƒãƒ©ãƒ³ã‚¹: {analysis['balance']}")
        print(f"æ¨å¥¨: {analysis['recommendation']}")
        
        # Directorè©•ä¾¡ã‚’å®Ÿè¡Œ
        evaluation = await manager.director.evaluate_dialogue(test_case['dialogues'])
        
        print(f"\nDirectoråˆ¤æ–­:")
        print(f"  ä»‹å…¥å¿…è¦: {evaluation.get('intervention_needed', False)}")
        print(f"  ç†ç”±: {evaluation.get('reason', 'ä¸æ˜')}")
        print(f"  ã‚¿ã‚¤ãƒ—: {evaluation.get('intervention_type', 'ãªã—')}")
        print(f"  é•·ã•ã‚¬ã‚¤ãƒ‰: {evaluation.get('response_length_guide', 'ç¾çŠ¶ç¶­æŒ')}")
        
        if evaluation.get('message'):
            print(f"  ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {evaluation['message']}")
        
        # é•·ã•æŒ‡ç¤ºã®ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        if evaluation.get('response_length_guide') != 'ç¾çŠ¶ç¶­æŒ':
            instruction = manager.director.generate_length_instruction(
                evaluation['response_length_guide']
            )
            print(f"\nç”Ÿæˆã•ã‚ŒãŸé•·ã•æŒ‡ç¤º:")
            print(instruction)
    
    print("\n" + "=" * 60)
    print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")

def test_prompt_generation():
    """é•·ã•æŒ‡ç¤ºã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ"""
    
    print("\n" + "=" * 60)
    print("ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    from app.core.agent import Agent
    
    # ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    agent = Agent(
        agent_id="test",
        character_type="AI-tuber-college_student_girl",
        model_name="qwen2.5:7b-instruct-q4_K_M",
        ollama_client=ollama.Client()
    )
    
    # é•·ã•æŒ‡ç¤ºã‚’è¿½åŠ 
    test_cases = [
        ("ç°¡æ½”", ["50-100æ–‡å­—ã§ç°¡æ½”ã«", "è¦ç‚¹ã®ã¿"]),
        ("æ¨™æº–", ["100-200æ–‡å­—ç¨‹åº¦ã§", "é©åº¦ãªè©³ã—ã•"]),
        ("è©³ç´°", ["200-300æ–‡å­—ã§è©³ã—ã", "å…·ä½“ä¾‹ã‚’å«ã‚ã¦"])
    ]
    
    for length_type, attention_points in test_cases:
        print(f"\n--- {length_type}ã®å ´åˆ ---")
        
        agent.add_directive(
            f"æ¬¡ã®å¿œç­”ã¯{length_type}ã«ã¾ã¨ã‚ã¦ãã ã•ã„",
            attention_points
        )
        
        context = {
            "opponent_name": "ã‚ã‚†",
            "opponent_message": "ã‚„ãªå§‰ã•ã¾ã€AIã®æ„Ÿæƒ…ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
            "recent_history": [],
            "director_instruction": ""
        }
        
        prompt = agent.build_prompt(context)
        
        # é•·ã•æŒ‡ç¤ºéƒ¨åˆ†ã‚’æŠ½å‡ºã—ã¦è¡¨ç¤º
        if "ã€å¿œç­”ã®é•·ã•ã€‘" in prompt:
            length_part = prompt.split("ã€å¿œç­”ã®é•·ã•ã€‘")[1].split("\n")[0]
            print(f"é•·ã•æŒ‡ç¤º: {length_part}")
        else:
            print("é•·ã•æŒ‡ç¤ºãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
    
    print("\n" + "=" * 60)
    print("âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    # éåŒæœŸãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    print("\nğŸš€ é•·ã•åˆ¶å¾¡æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™\n")
    
    try:
        # é•·ã•åˆ†æã¨Directorè©•ä¾¡ã®ãƒ†ã‚¹ãƒˆ
        asyncio.run(test_length_control())
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ
        test_prompt_generation()
        
        print("\nâœ¨ å…¨ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. streamlit run app/pages/03_Advanced_Dialogue.py")
        print("2. å¿œç­”é•·åˆ¶å¾¡ã‚’ã€Œç°¡æ½”ã€ã€Œæ¨™æº–ã€ã€Œè©³ç´°ã€ã§è©¦ã™")
        print("3. è‡ªå‹•é•·ã•ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã‚’ON/OFFã§æ¯”è¼ƒ")
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()